import{_ as n,r as i,o as l,c as r,a as e,e as a}from"./app-v6gVLxUV.js";const c={},d=e("h2",{id:"abstract",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#abstract"},[e("span",null,"Abstract")])],-1),m=e("p",null,"The common practice in developing computer-aided diagnosis (CAD) models based on transformer architectures usually involves fine-tuning from ImageNet pre-trained weights. However, with recent advances in large-scale pre-training and the practice of scaling laws, Vision Transformers (ViT) have become much larger and less accessible to medical imaging communities. Additionally, in real-world scenarios, the deployments of multiple CAD models can be troublesome due to problems such as limited storage space and time-consuming model switching. To address these challenges, we propose a new method MeLo (Medical image Low-rank adaptation), which enables the development of a single CAD model for multiple clinical tasks in a lightweight manner. It adopts low-rank adaptation instead of resource-demanding fine-tuning. By fixing the weight of ViT models and only adding small low-rank plug-ins, we achieve competitive results on various diagnosis tasks across different imaging modalities using only a few trainable parameters. Specifically, our proposed method achieves comparable performance to fully fine-tuned ViT models on four distinct medical imaging datasets using about 0.17% trainable parameters. Moreover, MeLo adds only about 0.5MB of storage space and allows for extremely fast model switching in deployment and inference.",-1),h=e("h2",{id:"model",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#model"},[e("span",null,"Model")])],-1),g={style:{display:"flex","flex-wrap":"wrap",gap:"16px"}},p=e("h2",{id:"我的页面",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#我的页面"},[e("span",null,"我的页面")])],-1);function u(_,b){const t=i("Card"),s=i("MyComponent"),o=i("Giscus");return l(),r("div",null,[d,m,h,e("div",g,[a(t,{image:"/image/sz_chest_xray.png",title:"SZ Chest X-ray",Task:"Tuberculosis Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/ChinaSetAllFiles_base_lora_4_4.safetensors"}),a(t,{image:"/image/bloodcell.jpg",title:"Bloodcell",Task:"Blood Cell Identification",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/blood-cells_base_lora_4_4.safetensors"}),a(t,{image:"/image/nih_chest_xray.jpg",title:"NIH Chest X-ray",Task:"Thoracic Disease Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/nih_base1_lora_4_4.safetensors"}),a(t,{image:"/image/mamo.jpg",title:"INBreast",Task:"Breast Malignancy Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/inbreast_base1_lora_4_4.safetensors"})]),p,a(s),a(o)])}const w=n(c,[["render",u],["__file","index.html.vue"]]),k=JSON.parse('{"path":"/model/","title":"","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Model","slug":"model","link":"#model","children":[]},{"level":2,"title":"我的页面","slug":"我的页面","link":"#我的页面","children":[]}],"git":{"updatedTime":1725352726000,"contributors":[{"name":"So-cean","email":"913902676@qq.com","commits":3}]},"filePathRelative":"model/README.md"}');export{w as comp,k as data};
