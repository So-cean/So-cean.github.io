import{_ as l,r as i,o as r,c as d,a as e,d as t}from"./app-XoJGMUZM.js";const m={},c={style:{display:"flex","flex-wrap":"wrap",gap:"16px"}};function g(h,a){const o=i("Card"),s=i("MyComponent"),n=i("Giscus");return r(),d("div",null,[a[0]||(a[0]=e("h2",{id:"abstract",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#abstract"},[e("span",null,"Abstract")])],-1)),a[1]||(a[1]=e("p",null,"The common practice in developing computer-aided diagnosis (CAD) models based on transformer architectures usually involves fine-tuning from ImageNet pre-trained weights. However, with recent advances in large-scale pre-training and the practice of scaling laws, Vision Transformers (ViT) have become much larger and less accessible to medical imaging communities. Additionally, in real-world scenarios, the deployments of multiple CAD models can be troublesome due to problems such as limited storage space and time-consuming model switching. To address these challenges, we propose a new method MeLo (Medical image Low-rank adaptation), which enables the development of a single CAD model for multiple clinical tasks in a lightweight manner. It adopts low-rank adaptation instead of resource-demanding fine-tuning. By fixing the weight of ViT models and only adding small low-rank plug-ins, we achieve competitive results on various diagnosis tasks across different imaging modalities using only a few trainable parameters. Specifically, our proposed method achieves comparable performance to fully fine-tuned ViT models on four distinct medical imaging datasets using about 0.17% trainable parameters. Moreover, MeLo adds only about 0.5MB of storage space and allows for extremely fast model switching in deployment and inference.",-1)),a[2]||(a[2]=e("h2",{id:"model",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#model"},[e("span",null,"Model")])],-1)),e("div",c,[t(o,{image:"/image/sz_chest_xray.png",title:"SZ Chest X-ray",Task:"Tuberculosis Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/ChinaSetAllFiles_base_lora_4_4.safetensors",routePath:"/model/AdrenalMNIST/"}),t(o,{image:"/image/bloodcell.jpg",title:"Bloodcell",Task:"Blood Cell Identification",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/blood-cells_base_lora_4_4.safetensors",routePath:"/model/AdrenalMNIST/"}),t(o,{image:"/image/nih_chest_xray.jpg",title:"NIH Chest X-ray",Task:"Thoracic Disease Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/nih_base1_lora_4_4.safetensors",routePath:"/model/AdrenalMNIST/"}),t(o,{image:"/image/mamo.jpg",title:"INBreast",Task:"Breast Malignancy Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/inbreast_base1_lora_4_4.safetensors",routePath:"/model/AdrenalMNIST/"})]),a[3]||(a[3]=e("h2",{id:"我的页面",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#我的页面"},[e("span",null,"我的页面")])],-1)),t(s),t(n)])}const u=l(m,[["render",g],["__file","index.html.vue"]]),b=JSON.parse('{"path":"/model/","title":"","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Model","slug":"model","link":"#model","children":[]},{"level":2,"title":"我的页面","slug":"我的页面","link":"#我的页面","children":[]}],"git":{"updatedTime":1726146189000,"contributors":[{"name":"So-cean","email":"913902676@qq.com","commits":5}]},"filePathRelative":"model/README.md"}');export{u as comp,b as data};
