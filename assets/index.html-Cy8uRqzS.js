import{_ as s,r as i,o as n,c as l,a as e,e as a}from"./app-CAwTmyel.js";const r={},d=e("h2",{id:"abstract",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#abstract"},[e("span",null,"Abstract")])],-1),c=e("p",null,"The common practice in developing computer-aided diagnosis (CAD) models based on transformer architectures usually involves fine-tuning from ImageNet pre-trained weights. However, with recent advances in large-scale pre-training and the practice of scaling laws, Vision Transformers (ViT) have become much larger and less accessible to medical imaging communities. Additionally, in real-world scenarios, the deployments of multiple CAD models can be troublesome due to problems such as limited storage space and time-consuming model switching. To address these challenges, we propose a new method MeLo (Medical image Low-rank adaptation), which enables the development of a single CAD model for multiple clinical tasks in a lightweight manner. It adopts low-rank adaptation instead of resource-demanding fine-tuning. By fixing the weight of ViT models and only adding small low-rank plug-ins, we achieve competitive results on various diagnosis tasks across different imaging modalities using only a few trainable parameters. Specifically, our proposed method achieves comparable performance to fully fine-tuned ViT models on four distinct medical imaging datasets using about 0.17% trainable parameters. Moreover, MeLo adds only about 0.5MB of storage space and allows for extremely fast model switching in deployment and inference.",-1),m=e("h2",{id:"model",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#model"},[e("span",null,"Model")])],-1),h={style:{display:"flex","flex-wrap":"wrap",gap:"16px"}},g=e("h2",{id:"我的页面",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#我的页面"},[e("span",null,"我的页面")])],-1);function p(u,b){const t=i("Card"),o=i("MyComponent");return n(),l("div",null,[d,c,m,e("div",h,[a(t,{image:"/image/sz_chest_xray.png",title:"SZ Chest X-ray",Task:"Tuberculosis Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/ChinaSetAllFiles_base_lora_4_4.safetensors"}),a(t,{image:"/image/bloodcell.jpg",title:"Bloodcell",Task:"Blood Cell Identification",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/blood-cells_base_lora_4_4.safetensors"}),a(t,{image:"/image/nih_chest_xray.jpg",title:"NIH Chest X-ray",Task:"Thoracic Disease Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/nih_base1_lora_4_4.safetensors"}),a(t,{image:"/image/mamo.jpg",title:"INBreast",Task:"Breast Malignancy Diagnosis",ViT:"base-ImageNet",Rank:"4",downloadlink:"https://absterzhu.github.io/melo.github.io/static/melo/inbreast_base1_lora_4_4.safetensors"})]),g,a(o)])}const f=s(r,[["render",p],["__file","index.html.vue"]]),w=JSON.parse('{"path":"/model/","title":"","lang":"en-US","frontmatter":{},"headers":[{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Model","slug":"model","link":"#model","children":[]},{"level":2,"title":"我的页面","slug":"我的页面","link":"#我的页面","children":[]}],"git":{"updatedTime":1722434695000,"contributors":[{"name":"So-cean","email":"913902676@qq.com","commits":2}]},"filePathRelative":"model/README.md"}');export{f as comp,w as data};
